{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiments on wiki dataset including:\n",
    "* Pretrained Glove\n",
    "* Our TT model with Glove init for different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "random.seed(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/workspace/tt-pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import t3nsor as t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if USE_CUDA else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if USE_CUDA else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if USE_CUDA else torch.ByteTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if USE_CUDA else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, word2index):\n",
    "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
    "    return LongTensor(idxs)\n",
    "\n",
    "def prepare_word(word, word2index):\n",
    "    return LongTensor([word2index[word]]) if word2index.get(word) is not None else LongTensor([word2index[\"<UNK>\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"/workspace/data/enwik8.txt\", dtype=str, delimiter='.')\n",
    "\n",
    "corpus = [data[i].split() for i in data.nonzero()[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude sparse words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = Counter(flatten(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_COUNT = 100\n",
    "exclude = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w, c in word_count.items():\n",
    "    if c < MIN_COUNT:\n",
    "        exclude.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203668"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(set(flatten(corpus)) - set(exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9603"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {}\n",
    "for vo in vocab:\n",
    "    if word2index.get(vo) is None:\n",
    "        word2index[vo] = len(word2index)\n",
    "        \n",
    "index2word = {v:k for k, v in word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "889156"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 5\n",
    "\n",
    "s = WINDOW_SIZE // 2\n",
    "\n",
    "train_data = []\n",
    "\n",
    "for tmp, sentence in enumerate(corpus):\n",
    "    l = len(sentence)\n",
    "    for i in range(l):\n",
    "        for j in range(max(0,i-s), min(i+s+1,l)):\n",
    "            if (i != j and (sentence[i] in word2index) \\\n",
    "                and (sentence[j] in word2index)):\n",
    "                c = sentence[j]\n",
    "                w = sentence[i]\n",
    "                \n",
    "                train_data.append((word2index[w], word2index[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Unigram Distribution**0.75 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(w)=U(w)^{3/4}/Z$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = Counter(flatten(corpus))\n",
    "num_total_words = sum([c for w, c in word_count.items() if w not in exclude])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_table = []\n",
    "\n",
    "for vo in vocab:\n",
    "    unigram_table.extend([vo] * int(((word_count[vo]/num_total_words)**0.75)/Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(vocab), len(unigram_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_sampling(targets, unigram_table, k):\n",
    "    batch_size = targets.size(0)\n",
    "    neg_samples = []\n",
    "    for i in range(batch_size):\n",
    "        nsample = []\n",
    "        target_index = targets[i].item()\n",
    "        while len(nsample) < k: # num of sampling\n",
    "            neg = random.choice(unigram_table)\n",
    "            if word2index[neg] == target_index:\n",
    "                continue\n",
    "            nsample.append(neg)\n",
    "        neg_samples.append(prepare_sequence(nsample, word2index).view(1, -1))\n",
    "    \n",
    "    return torch.cat(neg_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bcolz, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "idx = 0\n",
    "word2idx = {}\n",
    "vectors = bcolz.carray(np.zeros(1), rootdir=f'/workspace/glove/6B.50.dat', mode='w')\n",
    "\n",
    "with open(f'/workspace/glove/glove.6B.50d.txt', 'rb') as f:\n",
    "    print(\"opening file..\")\n",
    "    for l in f:\n",
    "        line = l.decode().split()\n",
    "        word = line[0]\n",
    "        words.append(word)\n",
    "        word2idx[word] = idx\n",
    "        idx += 1\n",
    "        vect = np.array(line[1:]).astype(np.float)\n",
    "        vectors.append(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = bcolz.carray(vectors[1:].reshape((400001, 50)), rootdir=f'/workspace/glove/6B.50.dat', mode='w')\n",
    "vectors.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(words, open(f'/workspace/glove/6B.50_words.pkl', 'wb'))\n",
    "pickle.dump(word2idx, open(f'/workspace/glove/6B.50_idx.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = bcolz.open(f'/workspace/glove/6B.50.dat')[:]\n",
    "words = pickle.load(open(f'/workspace/glove/6B.50_words.pkl', 'rb'))\n",
    "word2idx = pickle.load(open(f'/workspace/glove/6B.50_idx.pkl', 'rb'))\n",
    "\n",
    "glove = {w: vectors[word2idx[w]] for w in words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.37085 , -0.072561, -0.44149 ,  0.28066 , -0.16122 ,  0.81921 ,\n",
       "       -1.1913  , -0.14747 , -0.90533 , -0.91049 , -0.80279 ,  0.52766 ,\n",
       "       -0.71711 , -0.068202,  0.85043 , -0.14513 ,  0.47629 ,  0.57743 ,\n",
       "       -0.56997 , -0.59035 , -0.26699 , -0.01678 ,  0.29088 , -0.2056  ,\n",
       "        0.015951, -1.5403  , -0.10613 ,  0.34189 , -0.42333 , -0.094656,\n",
       "        0.49382 , -0.19415 , -0.67599 , -0.014195, -0.15302 , -0.4968  ,\n",
       "       -0.1013  ,  0.45619 , -0.28205 , -0.28014 ,  0.17112 ,  1.057   ,\n",
       "       -0.99511 , -0.58887 ,  0.72242 ,  0.051293, -0.59036 ,  0.29768 ,\n",
       "       -0.94829 ,  1.9092  ])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['dick']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9603"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_len = len(vocab)\n",
    "weights_matrix = np.zeros((matrix_len, 50))\n",
    "words_found = 0\n",
    "\n",
    "for i, word in enumerate(vocab):\n",
    "    try: \n",
    "        weights_matrix[i] = glove[word]\n",
    "        words_found += 1\n",
    "    except KeyError:\n",
    "        weights_matrix[i] = np.random.normal(scale=0.6, size=(50, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import subprocess\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_embed(vocab, embeds):\n",
    "    if len(vocab) < embeds.shape[0]:\n",
    "        embeds = embeds[:len(vocab), :]\n",
    "        \n",
    "    d = dict(zip(list(vocab.keys()), embeds))\n",
    "    \n",
    "    \n",
    "    fin = '/workspace/tt-pytorch/tmp1.pkl'\n",
    "    fout = '/workspace/tt-pytorch/tmp1.csv'\n",
    "    \n",
    "    print('Starting pickle')\n",
    "    with open(fin, 'wb') as f:\n",
    "        pickle.dump(d, f)\n",
    "        \n",
    "    print('Finished pickle')\n",
    "        \n",
    "    path = '/workspace/tt-pytorch/word-embeddings-benchmarks/scripts/evaluate_on_all.py'\n",
    "    script_full = 'python {path} --file {fname} --output {outname}'.format(path=path, \n",
    "                                                                 fname=fin, \n",
    "                                                                 outname=fout)\n",
    "    \n",
    "    print(script_full)\n",
    "    \n",
    "    subprocess.run([script_full], shell=True)\n",
    "    df = pd.read_csv(fout)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pickle\n",
      "Finished pickle\n",
      "python /workspace/tt-pytorch/word-embeddings-benchmarks/scripts/evaluate_on_all.py --file /workspace/tt-pytorch/tmp1.pkl --output /workspace/tt-pytorch/tmp1.csv\n"
     ]
    }
   ],
   "source": [
    "df = evaluate_embed(word2index, weights_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEN</th>\n",
       "      <th>MTurk</th>\n",
       "      <th>SimLex999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.318493</td>\n",
       "      <td>0.507134</td>\n",
       "      <td>0.20228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MEN     MTurk  SimLex999\n",
       "0  0.318493  0.507134    0.20228"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['MEN', 'MTurk', 'SimLex999']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx_cut = dict(zip(list(word2idx.keys())[:-1], np.arange(40000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TT ranks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "embds = np.zeros((9800, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "embds[:9603,:] = weights_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = [16, 32, 64, 128, 256, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pickle\n",
      "Finished pickle\n",
      "python /workspace/tt-pytorch/word-embeddings-benchmarks/scripts/evaluate_on_all.py --file /workspace/tt-pytorch/tmp1.pkl --output /workspace/tt-pytorch/tmp1.csv\n",
      "2 [[ 0.00129656 -0.111136    0.01444499]]\n",
      "Starting pickle\n",
      "Finished pickle\n",
      "python /workspace/tt-pytorch/word-embeddings-benchmarks/scripts/evaluate_on_all.py --file /workspace/tt-pytorch/tmp1.pkl --output /workspace/tt-pytorch/tmp1.csv\n",
      "4 [[ 0.01397857 -0.01816318  0.03506379]]\n",
      "Starting pickle\n",
      "Finished pickle\n",
      "python /workspace/tt-pytorch/word-embeddings-benchmarks/scripts/evaluate_on_all.py --file /workspace/tt-pytorch/tmp1.pkl --output /workspace/tt-pytorch/tmp1.csv\n",
      "8 [[-0.00404109  0.10894443  0.04813412]]\n",
      "Starting pickle\n",
      "Finished pickle\n",
      "python /workspace/tt-pytorch/word-embeddings-benchmarks/scripts/evaluate_on_all.py --file /workspace/tt-pytorch/tmp1.pkl --output /workspace/tt-pytorch/tmp1.csv\n",
      "16 [[0.00463707 0.05176925 0.07168481]]\n",
      "Starting pickle\n",
      "Finished pickle\n",
      "python /workspace/tt-pytorch/word-embeddings-benchmarks/scripts/evaluate_on_all.py --file /workspace/tt-pytorch/tmp1.pkl --output /workspace/tt-pytorch/tmp1.csv\n",
      "32 [[0.07767592 0.16590285 0.08503341]]\n",
      "Starting pickle\n",
      "Finished pickle\n",
      "python /workspace/tt-pytorch/word-embeddings-benchmarks/scripts/evaluate_on_all.py --file /workspace/tt-pytorch/tmp1.pkl --output /workspace/tt-pytorch/tmp1.csv\n",
      "64 [[0.246918   0.41704318 0.15041968]]\n",
      "Starting pickle\n",
      "Finished pickle\n",
      "python /workspace/tt-pytorch/word-embeddings-benchmarks/scripts/evaluate_on_all.py --file /workspace/tt-pytorch/tmp1.pkl --output /workspace/tt-pytorch/tmp1.csv\n",
      "128 [[0.31849257 0.50713427 0.20227968]]\n",
      "Starting pickle\n",
      "Finished pickle\n",
      "python /workspace/tt-pytorch/word-embeddings-benchmarks/scripts/evaluate_on_all.py --file /workspace/tt-pytorch/tmp1.pkl --output /workspace/tt-pytorch/tmp1.csv\n",
      "256 [[0.31849257 0.50713427 0.20227968]]\n"
     ]
    }
   ],
   "source": [
    "for rank in ranks:\n",
    "    tt_embds = t3.to_tt_matrix(torch.Tensor(embds).to(device), \n",
    "                               shape=[[8,25,49], [5,5,2]], max_tt_rank=rank)\n",
    "    \n",
    "    embds_full = tt_embds.full()\n",
    "    embds_cut = embds_full.detach().cpu().numpy()[:9603, :]\n",
    "    \n",
    "    df = evaluate_embed(word2index, embds_cut)\n",
    "    cur_result = np.array(df[['MEN', 'MTurk', 'SimLex999']])\n",
    "    results.append(cur_result)\n",
    "    print(rank, cur_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_embds = t3.to_tt_matrix(torch.Tensor(embds).to(device), \n",
    "                               shape=[[8,25,49], [5,5,2]], max_tt_rank=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A TT-Matrix of size 9800 x 50, underlying tensorshape: [8, 25, 49] x [5, 5, 2], TT-ranks: [1, 40, 64, 1] \n",
      " on device 'cuda:0' with compression rate 1.49\n"
     ]
    }
   ],
   "source": [
    "print(tt_embds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 50)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "embds = vectors[:-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = [16, 32, 64, 128, 256, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4 * 100000 == 4 * 10 * 10 * 10 * 10 * 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pickle\n",
      "Finished pickle\n",
      "python /workspace/tt-pytorch/word-embeddings-benchmarks/scripts/evaluate_on_all.py --file /workspace/tt-pytorch/tmp1.pkl --output /workspace/tt-pytorch/tmp1.csv\n",
      "16 [[ 0.08090662  0.11002691 -0.11075207]]\n",
      "Starting pickle\n",
      "Finished pickle\n",
      "python /workspace/tt-pytorch/word-embeddings-benchmarks/scripts/evaluate_on_all.py --file /workspace/tt-pytorch/tmp1.pkl --output /workspace/tt-pytorch/tmp1.csv\n",
      "32 [[ 0.08557271  0.14092777 -0.10232093]]\n",
      "Starting pickle\n",
      "Finished pickle\n",
      "python /workspace/tt-pytorch/word-embeddings-benchmarks/scripts/evaluate_on_all.py --file /workspace/tt-pytorch/tmp1.pkl --output /workspace/tt-pytorch/tmp1.csv\n",
      "64 [[ 0.07682954  0.11284035 -0.09828222]]\n",
      "Starting pickle\n",
      "Finished pickle\n",
      "python /workspace/tt-pytorch/word-embeddings-benchmarks/scripts/evaluate_on_all.py --file /workspace/tt-pytorch/tmp1.pkl --output /workspace/tt-pytorch/tmp1.csv\n",
      "128 [[ 0.09364144  0.14017365 -0.10043336]]\n",
      "Starting pickle\n",
      "Finished pickle\n",
      "python /workspace/tt-pytorch/word-embeddings-benchmarks/scripts/evaluate_on_all.py --file /workspace/tt-pytorch/tmp1.pkl --output /workspace/tt-pytorch/tmp1.csv\n",
      "256 [[ 0.14365637  0.1888938  -0.07556944]]\n",
      "Starting pickle\n",
      "Finished pickle\n",
      "python /workspace/tt-pytorch/word-embeddings-benchmarks/scripts/evaluate_on_all.py --file /workspace/tt-pytorch/tmp1.pkl --output /workspace/tt-pytorch/tmp1.csv\n",
      "512 [[0.2969699  0.35842452 0.00913411]]\n"
     ]
    }
   ],
   "source": [
    "for rank in ranks:\n",
    "    tt_embds = t3.to_tt_matrix(torch.Tensor(embds).to(device), \n",
    "                               shape=[[400, 100, 10], [5, 5, 2]], max_tt_rank=rank)\n",
    "    \n",
    "    embds_full = tt_embds.full()\n",
    "    embds_cut = embds_full.detach().cpu().numpy()\n",
    "    \n",
    "    df = evaluate_embed(word2idx_cut, embds_cut)\n",
    "    cur_result = np.array(df[['MEN', 'MTurk', 'SimLex999']])\n",
    "    results.append(cur_result)\n",
    "    print(rank, cur_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 50)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embds_cut.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2idx_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
