{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import t3nsor as t3\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(tokenize='spacy');\n",
    "LABEL = data.LabelField(dtype=torch.float);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "file = open(\"data/enwik8.txt\", \"r\")\n",
    "doclist = [ line for line in file ]\n",
    "docstr = '' . join(doclist)\n",
    "sentences = re.split(r'[.!?]', docstr)\n",
    "sentences = [sentence.split() for sentence in sentences if len(sentence) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "889156"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load enwik 8\n",
    "data = np.loadtxt(\"data/enwik8.txt\", dtype=str, delimiter='.')\n",
    "\n",
    "# Create a list of sentences\n",
    "sentences = [data[i].split() for i in data.nonzero()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocabulary(sentences, r=200):\n",
    "    prevocabulary = {}\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            if word in prevocabulary:\n",
    "                prevocabulary[word] += 1\n",
    "            else:\n",
    "                prevocabulary[word] = 1\n",
    "\n",
    "    vocabulary = {}\n",
    "    idx = 0\n",
    "    for word in prevocabulary:\n",
    "        if (prevocabulary[word] > r):\n",
    "            vocabulary[word] = idx\n",
    "            idx += 1\n",
    "\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = create_vocabulary(sentences)\n",
    "inv_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corpus_matrix(sentences, vocabulary, window_size=5):\n",
    "    \"\"\"\n",
    "    Create a co-occurrence matrix D from training corpus.\n",
    "    \"\"\"\n",
    "\n",
    "    dim = len(vocabulary)\n",
    "    D = np.zeros((dim, dim))\n",
    "    s = window_size//2\n",
    "\n",
    "    for sentence in sentences:\n",
    "        l = len(sentence)\n",
    "        for i in range(l):\n",
    "            for j in range(max(0,i-s), min(i+s+1,l)):\n",
    "                if (i != j and (sentence[i] in vocabulary) \\\n",
    "                    and (sentence[j] in vocabulary)):\n",
    "                    c = vocabulary[sentence[j]]\n",
    "                    w = vocabulary[sentence[i]]\n",
    "                    D[c][w] += 1                  \n",
    "    return D.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = create_corpus_matrix(sentences, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, Sampler, DataLoader\n",
    "\n",
    "class CorpusDataset(Dataset):\n",
    "    def __init__(self, corpus_matrix):\n",
    "        self.D = corpus_matrix\n",
    "        self.B = self.D.sum(axis=0, keepdims=True) * \\\n",
    "            self.D.sum(axis=1, keepdims=True) / self.D.sum()\n",
    "        self.vocab_size = self.D.shape[0]\n",
    "        self.w, self.c = corpus_matrix.nonzero()\n",
    "        self.len = len(self.w)\n",
    "        self.data = {\n",
    "            (self.w[i], self.c[i]): self.D[self.w[i], self.c[i]]\n",
    "            for i in range(self.len)}\n",
    "        self.negative = {\n",
    "            (self.w[i], self.c[i]): self.B[self.w[i], self.c[i]]\n",
    "            for i in range(self.len)}\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        i, j = self.w[index], self.c[index]\n",
    "        dct = {\n",
    "            \"word\": i,\n",
    "            \"context\": j,\n",
    "            \"count\": self.data[(i, j)].astype(np.float32),\n",
    "            \"negative\": self.negative[(i, j)].astype(np.float32)}\n",
    "        return dct\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "\n",
    "class CorpusSampler(Sampler):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.len = len(self.dataset)\n",
    "        self.indices = np.arange(self.len)\n",
    "        np.random.shuffle(self.indices)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self.indices)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.w_emb = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=embedding_dim)\n",
    "        self.c_emb = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=embedding_dim)\n",
    "        self.init_emb()\n",
    "\n",
    "    def init_emb(self):\n",
    "        \"\"\"Initialize embedding weight like word2vec.\n",
    "        The w_emb is a uniform distribution in\n",
    "        [-0.5/em_size, 0.5/emb_size], and the elements\n",
    "        of c_embedding are zeroes.\n",
    "        \"\"\"\n",
    "        initrange = 0.5 / self.embedding_dim\n",
    "        self.w_emb.weight.data.uniform_(-initrange, initrange)\n",
    "        self.c_emb.weight.data.uniform_(-0, 0)\n",
    "\n",
    "    def forward(self, word_indices, context_indices):\n",
    "        w = self.w_emb.forward(word_indices)\n",
    "        c = self.c_emb.forward(context_indices)\n",
    "        return w, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEmbeeddings(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log1p_exp(input_tensor):\n",
    "    \"\"\" Computationally stable function for computing log(1+exp(x)).\n",
    "    \"\"\"\n",
    "    x = input_tensor * input_tensor.ge(0).to(torch.float32)\n",
    "    res = x + torch.log1p(\n",
    "        torch.exp(-torch.abs(input_tensor)))\n",
    "    return res\n",
    "\n",
    "\n",
    "class Word2Vec:\n",
    "    def __init__(\n",
    "            self,\n",
    "            skip_gram_model,\n",
    "            #context_embedding,\n",
    "            neg_sampling_param=5,\n",
    "            learning_rate=0.025):\n",
    "        self._device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        #self.w_emb = word_embedding.to(self._device)\n",
    "        #self.c_emb = context_embedding.to(self._device)\n",
    "        self.skip_gram = skip_gram_model.to(self._device)\n",
    "        self.optimizer = optim.Adam(\n",
    "            self.skip_gram.parameters(), lr=learning_rate)\n",
    "        #self.w_optimizer = optim.SGD(\n",
    "        #    self.w_emb.parameters(), lr=learning_rate)\n",
    "        #self.c_optimizer = optim.SGD(\n",
    "        #    self.c_emb.parameters(), lr=learning_rate)\n",
    "        self.k = neg_sampling_param\n",
    "        \n",
    "    def to_tensor(self, *args, **kwargs):\n",
    "        return torch.Tensor(*args, **kwargs).to(self._device)\n",
    "        \n",
    "    def train(self, batch):\n",
    "        words, contexts, counts, negatives = \\\n",
    "            batch[\"word\"], batch[\"context\"], \\\n",
    "            batch[\"count\"], batch[\"negative\"]\n",
    "        words = torch.LongTensor(words).to(self._device)\n",
    "        contexts = torch.LongTensor(contexts).to(self._device)\n",
    "        counts = self.to_tensor(counts)\n",
    "        negatives = self.to_tensor(negatives)\n",
    "        \n",
    "        #w_emb = self.w_emb(words)\n",
    "        #c_emb = self.c_emb(contexts)\n",
    "        w_emb, c_emb = self.skip_gram(words, contexts)\n",
    "        wc = torch.einsum(\"bi,bi->b\", (w_emb, c_emb))\n",
    "        loss = (log1p_exp(-wc) * counts + \\\n",
    "            self.k * negatives * log1p_exp(wc)).mean()\n",
    "        \n",
    "        # update embeddings parameters\n",
    "        #self.w_optimizer.zero_grad()\n",
    "        #self.c_optimizer.zero_grad()\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        #self.w_optimizer.step()\n",
    "        #self.c_optimizer.step()\n",
    "        \n",
    "        metrics = {\"loss\": loss.item()}\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CorpusDataset(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = D.shape[0]\n",
    "embedding_dim = 100\n",
    "batch_size = 50\n",
    "\n",
    "#word_emb = WordEmbedding(vocab_size, embedding_dim)\n",
    "#context_emb = WordEmbedding(vocab_size, embedding_dim)\n",
    "skip_gram_model = SkipGramModel(vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(skip_gram_model, learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71582it [03:12, 371.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.47098362212908385\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71582it [03:12, 371.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.42904599728979576\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "71582it [03:15, 366.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.4216364210821891\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "71582it [03:11, 373.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.417201519145413\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71582it [03:13, 370.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.41536775999711906\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71582it [03:12, 372.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.41330510919017016\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71582it [03:10, 375.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.4127467479686759\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71582it [03:20, 357.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.41200741522530193\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71582it [03:14, 367.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.4112967561578341\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epoch_losses = []\n",
    "losses = []\n",
    "\n",
    "for epoch in range(1, 10):\n",
    "    sampler = CorpusSampler(dataset)\n",
    "    loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=1,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "        sampler=sampler)\n",
    "\n",
    "    for i, batch in tqdm.tqdm(enumerate(loader)):\n",
    "        metrics = model.train(batch)\n",
    "        losses.append(metrics[\"loss\"])\n",
    "        #if (i % 100 == 0):\n",
    "        #    print (metrics[\"loss\"])\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        avg_loss = np.mean(losses) / batch_size\n",
    "        epoch_losses.append(avg_loss)\n",
    "        losses = []\n",
    "        print (\"Loss: \", avg_loss)\n",
    "        print (\"---------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa486d9f7f0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = torch.LongTensor(np.arange(vocab_size))[None, :]\n",
    "emb_matrix = model.skip_gram.w_emb(ws.to(model._device))[0].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordVectors:\n",
    "    \n",
    "    def __init__(self, vocabulary, embedding_matrix):\n",
    "        self.vocab = vocabulary\n",
    "        self.W = embedding_matrix\n",
    "        self.inv_vocab = {v: k for k, v in self.vocab.items()}\n",
    "        \n",
    "    def word_vector(self, word):\n",
    "        \"\"\" Takes word and returns its word vector.\n",
    "        \"\"\"\n",
    "        if word in self.vocab:\n",
    "            vec = self.W[:,int(self.vocab[word])]\n",
    "            vec = vec\n",
    "        else:\n",
    "            print (\"No such word in vocabulary.\")\n",
    "            vec = None\n",
    "            \n",
    "        return vec\n",
    "    \n",
    "    def nearest_words(self, word, top=10, display=False):\n",
    "        \"\"\" Takes word from the vocabulary and returns its top_n\n",
    "        nearest neighbors in terms of cosine similarity.\n",
    "        \"\"\"\n",
    "\n",
    "        vec = self.word_vector(word)[None, :]\n",
    "\n",
    "        cosines = cosine_similarity(self.W.T, vec)[:, 0]\n",
    "        args = np.argsort(cosines)[::-1]       \n",
    "\n",
    "        nws = []\n",
    "        for i in range(1, top+1):\n",
    "            nws.append((self.inv_vocab[args[i]], round(cosines[args[i]], 3)))\n",
    "            if (display):\n",
    "                print (self.inv_vocab[args[i]], round(cosines[args[i]], 3))\n",
    "        return nws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_model = WordVectors(vocab, emb_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('linguistic', 0.826),\n",
       " ('via', 0.82),\n",
       " ('org', 0.816),\n",
       " ('rough', 0.814),\n",
       " ('offer', 0.813),\n",
       " ('enter', 0.812),\n",
       " ('horse', 0.811),\n",
       " ('output', 0.808),\n",
       " ('bow', 0.807),\n",
       " ('screen', 0.802)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_model.nearest_words(\"bear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nine', 0.81),\n",
       " ('two', 0.728),\n",
       " ('seven', 0.725),\n",
       " ('eight', 0.714),\n",
       " ('six', 0.71),\n",
       " ('five', 0.693),\n",
       " ('october', 0.674),\n",
       " ('four', 0.669),\n",
       " ('three', 0.667),\n",
       " ('zero', 0.65)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_model.nearest_words(\"one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
